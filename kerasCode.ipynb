{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "62400\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "import csv\n",
    "import numpy\n",
    "\n",
    "\n",
    "ModelAnswers = []\n",
    "\n",
    "OutputVectors = []\n",
    "with open('OutputQall.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for i in range(80):\n",
    "        OutputVectors.append(next(reader))\n",
    "\n",
    "\n",
    "InputVectors = []\n",
    "with open('InputQall.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for i in range(80):\n",
    "        InputVectors.append(next(reader))\n",
    "\n",
    "for i in range(8):\n",
    "    foundModel=False\n",
    "    for j in range(10):\n",
    "        if foundModel == False:\n",
    "            if OutputVectors[i*10+j][10] == '1':\n",
    "                foundModel = True\n",
    "                ModelAnswers.append(InputVectors[i*10+j])\n",
    "    \n",
    "        \n",
    "        \n",
    "InputVectos = []\n",
    "for i in range(len(InputVectors)):\n",
    "    vec = InputVectors[i] + ModelAnswers[int(i/10)]\n",
    "    InputVectos.append(vec)\n",
    "    \n",
    "print(len(InputVectos))\n",
    "print(len(InputVectos[0]))\n",
    "    \n",
    "\n",
    "TestVecs = []\n",
    "InputVecs = []\n",
    "OutputVecs = []\n",
    "OutTestVeccs = []\n",
    "for i in range(len(InputVectos)):\n",
    "    if i % 10 ==5:\n",
    "        TestVecs.append(InputVectos[i])\n",
    "        OutTestVeccs.append(OutputVectors[i])\n",
    "        \n",
    "    else:\n",
    "        InputVecs.append(InputVectos[i])\n",
    "        OutputVecs.append(OutputVectors[i])\n",
    "        \n",
    "\n",
    "print(len(TestVecs))\n",
    "\n",
    "hm_epochs = 60\n",
    "n_classes = 11\n",
    "batch_size = 72#  540/6;\n",
    "chunk_size = 300\n",
    "n_chunks = 104\n",
    "lstm_size = 25\n",
    "\n",
    "\n",
    "InputVecs = numpy.array(InputVecs)\n",
    "OutputVecs=numpy.array(OutputVecs)\n",
    "TestVecs = numpy.array(TestVecs)\n",
    "OutTestVeccs = numpy.array(OutTestVeccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=lstm_size, activation='relu', input_dim=62400))\n",
    "model.add(Dense(units=lstm_size, activation='relu'))\n",
    "model.add(Dense(units=lstm_size, activation='relu'))\n",
    "model.add(Dense(units=lstm_size, activation='relu'))\n",
    "model.add(Dense(units=n_classes, activation='softmax'))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 25)                1560025   \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 11)                286       \n",
      "=================================================================\n",
      "Total params: 1,562,261\n",
      "Trainable params: 1,562,261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "72/72 [==============================] - 5s 71ms/step - loss: 2.4103 - acc: 0.0972\n",
      "Epoch 2/60\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 2.5910 - acc: 0.2500\n",
      "Epoch 3/60\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 2.0997 - acc: 0.3472\n",
      "Epoch 4/60\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 1.7255 - acc: 0.4167\n",
      "Epoch 5/60\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 1.4962 - acc: 0.5139\n",
      "Epoch 6/60\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 1.2596 - acc: 0.5694\n",
      "Epoch 7/60\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 1.1151 - acc: 0.6111\n",
      "Epoch 8/60\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.9680 - acc: 0.6806\n",
      "Epoch 9/60\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 0.8471 - acc: 0.7639\n",
      "Epoch 10/60\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.7226 - acc: 0.7778\n",
      "Epoch 11/60\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.6426 - acc: 0.8194\n",
      "Epoch 12/60\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.5788 - acc: 0.8333\n",
      "Epoch 13/60\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.5176 - acc: 0.8472\n",
      "Epoch 14/60\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 0.4726 - acc: 0.8611\n",
      "Epoch 15/60\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.4371 - acc: 0.8750\n",
      "Epoch 16/60\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.3997 - acc: 0.8750\n",
      "Epoch 17/60\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.3737 - acc: 0.8750\n",
      "Epoch 18/60\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.3530 - acc: 0.8750\n",
      "Epoch 19/60\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.3350 - acc: 0.8750\n",
      "Epoch 20/60\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.3169 - acc: 0.8750\n",
      "Epoch 21/60\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.3007 - acc: 0.8750\n",
      "Epoch 22/60\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.2860 - acc: 0.8889\n",
      "Epoch 23/60\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 0.2699 - acc: 0.8889\n",
      "Epoch 24/60\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.2540 - acc: 0.8889\n",
      "Epoch 25/60\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.2418 - acc: 0.8889\n",
      "Epoch 26/60\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.2289 - acc: 0.9028\n",
      "Epoch 27/60\n",
      "72/72 [==============================] - 5s 63ms/step - loss: 0.2139 - acc: 0.9028\n",
      "Epoch 28/60\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.2009 - acc: 0.9167\n",
      "Epoch 29/60\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 0.1878 - acc: 0.9306\n",
      "Epoch 30/60\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.1745 - acc: 0.9444\n",
      "Epoch 31/60\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.1622 - acc: 0.9722\n",
      "Epoch 32/60\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.1500 - acc: 0.9722\n",
      "Epoch 33/60\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.1376 - acc: 1.0000\n",
      "Epoch 34/60\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 0.1260 - acc: 1.0000\n",
      "Epoch 35/60\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.1140 - acc: 1.0000\n",
      "Epoch 36/60\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.1016 - acc: 1.0000\n",
      "Epoch 37/60\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.0892 - acc: 1.0000\n",
      "Epoch 38/60\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.0783 - acc: 1.0000\n",
      "Epoch 39/60\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.0680 - acc: 1.0000\n",
      "Epoch 40/60\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.0592 - acc: 1.0000\n",
      "Epoch 41/60\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.0514 - acc: 1.0000\n",
      "Epoch 42/60\n",
      "72/72 [==============================] - 5s 63ms/step - loss: 0.0443 - acc: 1.0000\n",
      "Epoch 43/60\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.0373 - acc: 1.0000\n",
      "Epoch 44/60\n",
      "72/72 [==============================] - 5s 67ms/step - loss: 0.0312 - acc: 1.0000\n",
      "Epoch 45/60\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 0.0261 - acc: 1.0000\n",
      "Epoch 46/60\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.0220 - acc: 1.0000\n",
      "Epoch 47/60\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.0187 - acc: 1.0000\n",
      "Epoch 48/60\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.0162 - acc: 1.0000\n",
      "Epoch 49/60\n",
      "72/72 [==============================] - 5s 63ms/step - loss: 0.0143 - acc: 1.0000\n",
      "Epoch 50/60\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 0.0126 - acc: 1.0000\n",
      "Epoch 51/60\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.0112 - acc: 1.0000\n",
      "Epoch 52/60\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.0099 - acc: 1.0000\n",
      "Epoch 53/60\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 0.0087 - acc: 1.0000\n",
      "Epoch 54/60\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 55/60\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 56/60\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 57/60\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 58/60\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 59/60\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 60/60\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.0038 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "train = model.fit(InputVecs, OutputVecs, epochs=hm_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "5\n",
      "2\n",
      "1\n",
      "9\n",
      "10\n",
      "7\n",
      "5\n",
      "[1.9661870e-03 1.0240508e-05 2.4254368e-07 2.8226969e-01 1.2608840e-03\n",
      " 4.1524091e-01 8.2464467e-06 2.9922575e-01 3.2065557e-08 1.6971386e-05\n",
      " 9.3511642e-07]\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(TestVecs)\n",
    "print(numpy.argmax(result[7]))\n",
    "print(numpy.argmax(result[6]))\n",
    "print(numpy.argmax(result[5]))\n",
    "print(numpy.argmax(result[4]))\n",
    "print(numpy.argmax(result[3]))\n",
    "print(numpy.argmax(result[2]))\n",
    "print(numpy.argmax(result[1]))\n",
    "print(numpy.argmax(result[0]))\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
